{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pycobra and scikit-learn\n",
    "\n",
    "This notebook demonstrates pycobras integration with the scikit-learn ecosystem.\n",
    "We will also give an example of pycobra's performance on some real world data-sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pycobra.cobra import Cobra\n",
    "from pycobra.ewa import Ewa\n",
    "from pycobra.diagnostics import Diagnostics\n",
    "from pycobra.visualisation import Visualisation\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a synthetic data-set just to show that the COBRA estimator is scikit-learn compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up our random data-set\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "# D1 = train machines; D2 = create COBRA; D3 = calibrate epsilon, alpha; D4 = testing\n",
    "n_features = 20\n",
    "D1, D2, D3, D4 = 200, 200, 200, 200\n",
    "D = D1 + D2 + D3 + D4\n",
    "X = rng.uniform(-1, 1, D * n_features).reshape(D, n_features)\n",
    "Y = np.power(X[:,1], 2) + np.power(X[:,3], 3) + np.exp(X[:,10]) \n",
    "# Y = np.power(X[:,0], 2) + np.power(X[:,1], 3)\n",
    "\n",
    "# training data-set\n",
    "X_train = X[:D1 + D2]\n",
    "X_test = X[D1 + D2 + D3:D1 + D2 + D3 + D4]\n",
    "X_eps = X[D1 + D2:D1 + D2 + D3]\n",
    "# for testing\n",
    "Y_train = Y[:D1 + D2]\n",
    "Y_test = Y[D1 + D2 + D3:D1 + D2 + D3 + D4]\n",
    "Y_eps = Y[D1 + D2:D1 + D2 + D3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to other scikit-learn estimators, we set up our machine by creating an object and then fitting it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cobra = Cobra(random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cobra(random_state=<mtrand.RandomState object at 0x1060c7a50>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cobra.fit(X_train, Y_train, epsilon=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see if our object can fit into the scikit-learn pipeline and GridSearch - and it can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "check_estimator(Cobra) #passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentially Weighted Average Aggregate\n",
    "\n",
    "Let us also demonstrate the EWA predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ewa = Ewa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ewa(random_state=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewa.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_estimator(Ewa) #passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the Cobra estimator, Ewa is also a scikit-learn compatible estimator. It also fits into the Visualisation class, like demonstarted in the [notebook](https://github.com/bhargavvader/pycobra/blob/master/notebooks/visualise.ipynb). \n",
    "\n",
    "### Predicting?\n",
    "\n",
    "Like the other scikit-learn predictors, we estimate on data by simply using the `predict()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = X_test[0].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6896518])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cobra.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67998475])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewa.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why pycobra?\n",
    "\n",
    "There are scikit-learn estimators which already perform well in basic regression tasks - why use pycobra?\n",
    "The Cobra estimator has the advantage of a theoretical bound on it's performance - this means it is supposed to perform at least as well as the estimators used to create it. The Ewa estimator also has similar bounds.\n",
    "\n",
    "pycobra also lets you compare the scikit-learn estimators used in the aggregation - unlike the ensemble methods for regression which scikit-learn has, pycobra's algorithms is actually built on other scikit-learn like estimators. \n",
    "\n",
    "### pycobra for classification\n",
    "\n",
    "pycobra also implements the classification algorithm as described by Mojirsheibani [1999] Combining Classifiers via Discretization, Journal of the American Statistical Association. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:-20]\n",
    "y = iris.target[:-20]\n",
    "X_test = iris.data[-20:]\n",
    "y_test = iris.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycobra.classifiercobra import ClassifierCobra\n",
    "check_estimator(ClassifierCobra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = ClassifierCobra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierCobra(random_state=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  2.,  1.,  1.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world datasets\n",
    "\n",
    "We have demonstrated in the regression notebook how pycobra works on synthetic data-sets. Let's see pycobra in action on some scikit-learn regression datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "diabetes_X_train = diabetes.data[:-40]\n",
    "diabetes_X_test = diabetes.data[-20:]\n",
    "# part of the data to find an appropriate epsilon\n",
    "diabetes_X_eps = diabetes.data[-40:-20]\n",
    "\n",
    "diabetes_y_train = diabetes.target[:-40]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "diabetes_y_eps = diabetes.target[-40:-20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're unaware of what epsilon value to choose for our data-sets so by passing `X_eps` and `y_eps` we can get an idea of what might be a good epsilon value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COBRA_diabetes = Cobra()\n",
    "COBRA_diabetes.fit(diabetes_X_train, diabetes_y_train, X_epsilon=diabetes_X_eps, y_epsilon=diabetes_y_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Predicting using the COBRA predictor is again similar to using a scikit-learn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COBRA_diabetes.predict(diabetes_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare our MSEs using the diagnostics class now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cobra_diagnostics = Diagnostics(COBRA_diabetes, diabetes_X_test, diabetes_y_test, load_MSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cobra_diagnostics.machine_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us similarily use COBRA on the Boston housing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "boston_X_train = boston.data[:-40]\n",
    "boston_X_test = boston.data[-20:]\n",
    "boston_X_eps = boston.data[-40:-20]\n",
    "\n",
    "boston_y_train = boston.target[:-40]\n",
    "boston_y_test = boston.target[-20:]\n",
    "boston_y_eps = boston.target[-40:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COBRA_boston = Cobra()\n",
    "COBRA_boston.fit(boston_X_train, boston_y_train, X_epsilon=boston_X_eps, y_epsilon=boston_y_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cobra_diagnostics = Diagnostics(COBRA_boston, boston_X_test, boston_y_test, load_MSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cobra_diagnostics.machine_MSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
